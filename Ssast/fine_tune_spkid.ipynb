{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81ab4af-2c32-4381-9d0e-367b7cb1d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ast_models\n",
    "from Dataset.dataset import load_LJSpeech\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87218562-c462-49ca-b053-cf19d26dcc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = load_LJSpeech('Dataset/pitch_scaling2.txt', speaker_emb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eec81b1-06bd-4a00-a10e-d4985cd0094f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3483"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2817363-0acc-497a-918f-eb7445cf67b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now load a SSL pretrained models from ./save_model/SSAST-Base-Frame-400.pth\n",
      "pretraining patch split stride: frequency=128, time=2\n",
      "pretraining patch shape: frequency=128, time=2\n",
      "pretraining patch array dimension: frequency=1, time=512\n",
      "pretraining number of patches=512\n",
      "fine-tuning patch split stride: frequncey=128, time=1\n",
      "fine-tuning number of patches=499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\torch\\nn\\functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_tdim = 500\n",
    "ast_mdl = ast_models.ASTModel(label_dim=1,\n",
    "                    fshape=128, tshape=2, fstride=128, tstride=1,\n",
    "                    input_fdim=128, input_tdim=input_tdim, model_size='base',\n",
    "                    pretrain_stage=False, load_pretrained_mdl_path='./save_model/SSAST-Base-Frame-400.pth')\n",
    "                      \n",
    "\n",
    "ast_mdl = ast_mdl.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4381bdd0-cd3b-45c1-bf47-769d44b6ea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-05\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch.optim.Adam(ast_mdl.parameters(), lr = learning_rate, betas=[0.5, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99b2bcf3-d8f9-4d48-9b29-681dbf6ac166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spk(num_eps):\n",
    "    for eps in range(num_eps):\n",
    "        i = 0\n",
    "        ast_mdl.train()\n",
    "        since = time.time()\n",
    "        for i, (fbank, embedding, label_freq, label_time) in enumerate(train_loader): #fbank: [B, D, T];  \n",
    "            fbank = fbank.cuda() #确保embedding的shape:[B, 192]\n",
    "            embedding = embedding.cuda()\n",
    "            label_freq = label_freq.cuda()\n",
    "            label_time = label_time.cuda()\n",
    "            \n",
    "            # #warming up\n",
    "            # if global_step <= 1000 and global_step % 50 == 0 and args.warmup == True:\n",
    "            #     for group_id, param_group in enumerate(optimizer.param_groups):\n",
    "            #         warm_lr = (global_step / 1000) * lr_list[group_id]\n",
    "            #         param_group['lr'] = warm_lr\n",
    "            #         print('warm-up learning rate is {:f}'.format(param_group['lr']))                 \n",
    "                    \n",
    "            pred_freq, pred_time = ast_mdl(fbank, x_vector=embedding, task='ft_spk') #\n",
    "            \n",
    "            loss_freq = loss_fn(pred_freq.float(), label_freq.float())\n",
    "            loss_time = loss_fn(pred_time.float(), label_time.float())\n",
    "            loss = 1*loss_freq + 1*loss_time #set two hyperparemeters\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if i % 32 == 0:\n",
    "                print ('.', end='')\n",
    "            i += 1\n",
    "            \n",
    "            \n",
    "        time_elapsed = time.time() - since    \n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        \n",
    "        if eps % 1 == 0:    \n",
    "            print('loss:', loss, '\\n' 'loss_freq:', loss_freq, '\\n' 'loss_time:',loss_time)\n",
    "\n",
    "\n",
    "        if (eps + 1) % 5 == 0:\n",
    "            torch.save(ast_mdl.state_dict(), 'save_model/ft_spk2'+str(eps)+'.pth')\n",
    "            print ('Saving checkpoint for epoch {} at {}'.format(eps,\n",
    "                                            'save_model/ft_spk2'+str(eps)+'.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "369ff004-4758-4d46-8f8c-005c0b89fbf9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................................Training complete in 36m 1s\n",
      "loss: tensor(0.0275, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "loss_freq: tensor(0.0256, device='cuda:0', grad_fn=<MseLossBackward0>) \n",
      "loss_time: tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      ".............................................................................................................Training complete in 35m 51s\n",
      "loss: tensor(0.0317, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "loss_freq: tensor(0.0301, device='cuda:0', grad_fn=<MseLossBackward0>) \n",
      "loss_time: tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      ".............................................................................................................Training complete in 35m 57s\n",
      "loss: tensor(0.0312, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "loss_freq: tensor(0.0287, device='cuda:0', grad_fn=<MseLossBackward0>) \n",
      "loss_time: tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      ".............................................................................................................Training complete in 35m 57s\n",
      "loss: tensor(0.0299, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "loss_freq: tensor(0.0280, device='cuda:0', grad_fn=<MseLossBackward0>) \n",
      "loss_time: tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      ".............................................................................................................Training complete in 35m 57s\n",
      "loss: tensor(0.0188, device='cuda:0', grad_fn=<AddBackward0>) \n",
      "loss_freq: tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>) \n",
      "loss_time: tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "Saving checkpoint for epoch 4 at save_model/ft_spk24.pth\n",
      "......"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\LYC\\AppData\\Local\\Temp/ipykernel_7488/3894772195.py\", line 1, in <module>\n",
      "    train_spk(100)\n",
      "  File \"C:\\Users\\LYC\\AppData\\Local\\Temp/ipykernel_7488/941379688.py\", line 26, in train_spk\n",
      "    opt.step()\n",
      "  File \"D:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 88, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\torch\\optim\\adam.py\", line 133, in step\n",
      "    F.adam(params_with_grad,\n",
      "  File \"D:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\torch\\optim\\_functional.py\", line 98, in adam\n",
      "    param.addcdiv_(exp_avg, denom, value=-step_size)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\anaconda\\envs\\pytorch19\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\anaconda\\envs\\pytorch19\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\anaconda\\envs\\pytorch19\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\anaconda\\envs\\pytorch19\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"D:\\anaconda\\envs\\pytorch19\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7488/3894772195.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_spk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7488/941379688.py\u001b[0m in \u001b[0;36mtrain_spk\u001b[1;34m(num_eps)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2063\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2064\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2066\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "train_spk(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "270ff5a7-55f5-4185-be8c-73d010e81a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 15 at save_model/ft_spk15.pth\n"
     ]
    }
   ],
   "source": [
    "eps = 15\n",
    "torch.save(ast_mdl.state_dict(), 'save_model/ft_spk'+str(eps)+'.pth')\n",
    "print ('Saving checkpoint for epoch {} at {}'.format(eps,\n",
    "                                            'save_model/ft_spk'+str(eps)+'.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7778b1b-9c8a-43e9-b260-271d8c4e6d5d",
   "metadata": {},
   "source": [
    "##### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb267f61-dccf-44b2-b7ca-e8b65fc1a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel(audio, sr):\n",
    "    audio_norm = audio / 32768.0\n",
    "    audio_norm = audio_norm.unsqueeze(0)\n",
    "    audio_norm = torch.autograd.Variable(audio_norm, requires_grad=False)\n",
    "    # melspec = self.stft(sr).mel_spectrogram(audio_norm)\n",
    "    melspec = torchaudio.compliance.kaldi.fbank(audio, htk_compat=True, sample_frequency=sr, use_energy=False,\n",
    "                                                    window_type='hanning', num_mel_bins=128, dither=0.0, frame_shift=10)\n",
    "         \n",
    "    melspec = torch.squeeze(melspec, 0)\n",
    "    # melspec = torch.transpose(melspec, 0, 1)\n",
    "        \n",
    "    #cut and pad\n",
    "    target_length = 500\n",
    "    n_frames = melspec.shape[0]\n",
    "    p = target_length - n_frames\n",
    "\n",
    "    if p > 0:\n",
    "        m = torch.nn.ZeroPad2d((0, 0, 0, p))\n",
    "        melspec = m(melspec)\n",
    "    elif p < 0:\n",
    "        melspec = melspec[0:target_length, :]\n",
    "   \n",
    "    return melspec #(T, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8c6e93-5486-42f8-bc65-bdca028281fa",
   "metadata": {},
   "source": [
    "#### eval 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f266ce8c-7c16-460f-8958-4f90cb164911",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASTModel(\n",
       "  (v): DistilledVisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(1, 768, kernel_size=(128, 2), stride=(128, 1))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (pre_logits): Identity()\n",
       "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    (head_dist): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (mlp_head): Sequential(\n",
       "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=768, out_features=1536, bias=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=1536, out_features=1, bias=True)\n",
       "  )\n",
       "  (mlp_head2): Sequential(\n",
       "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=768, out_features=1536, bias=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=1536, out_features=1, bias=True)\n",
       "  )\n",
       "  (speaker_embedding): Sequential(\n",
       "    (0): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=192, out_features=768, bias=True)\n",
       "    (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('./save_model/ft_spk24.pth')\n",
    "ast_mdl.load_state_dict(state_dict, strict=False)\n",
    "ast_mdl.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e548b7-f6af-4748-be65-9143742e2530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n",
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n",
      "D:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:39: FutureWarning: Pass library_name=False as keyword args. From version 0.7 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from speechbrain.pretrained import EncoderClassifier\n",
    "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "411379a3-df7f-4f26-a918-f2ffb397cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_org, sr_org =torchaudio.load('E:/datasets/project3/AISHELL-3/train/wav/SSB0018/SSB00180007.wav')\n",
    "audio, sr =torchaudio.load('E:/datasets/project3/AISHELL-3/scaled/SSB0073/SSB00730025_fn7_t0.6000000000000001.wav')\n",
    "mel = get_mel(audio, sr).unsqueeze(0).cuda()\n",
    "emb = classifier.encode_batch(audio_org).squeeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a92a4747-f0ce-4555-be1f-a92d2af7f010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 500, 128]) torch.Size([1, 192])\n"
     ]
    }
   ],
   "source": [
    "print(mel.shape, emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaea6a5f-543c-4675-9c57-e6862f9d2b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_freq, pred_time = ast_mdl(mel, x_vector=emb, task='ft_spk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "848e3f1a-2259-4aa9-8cfb-b951f90cd118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.9591]], device='cuda:0', grad_fn=<MulBackward0>) tensor([[0.5498]], device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(pred_freq, pred_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57365084-cb8c-4cb2-a30c-536ed2035c6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de5c2ce9-b322-4464-b37b-c1310a7276b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.843587129994475"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "12*np.log2(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eea39086-52b4-4a16-8e0b-fd7a9fc81376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45999999999999996"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.58-1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22f4e623-dcf3-43cd-9be7-08b5a74f3e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab286e25-dd6c-4ebb-99cf-4b79e3e4c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5bafeb15-3d27-4e83-b402-7d143c8ba219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5132679772109018"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/1.9483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a666b489-a0b7-46d8-874a-66ab6a97f8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.552620999999999"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-10.928821+3.3762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0a3ba830-89ce-46df-86d5-dd40415eda24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.6762999999999995"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-10.2898+4.6135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5281c-0d3e-4a8e-bb3d-73614906efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "6.7532,6.8445,6.688,6.7,-4.2455,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2ea836-7394-48d3-83af-1b272a530717",
   "metadata": {},
   "source": [
    "#### eval 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "47c1b5ae-702f-43d6-84c6-af913e417e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['speaker_embedding.0.weight', 'speaker_embedding.0.bias', 'speaker_embedding.1.weight', 'speaker_embedding.1.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('./save_model/ft15.pth')\n",
    "ast_mdl.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "028f43ad-7cd3-4744-a87d-260249213a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_freq, pred_time = ast_mdl(mel, task='ft_cls2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "82b812c2-6f6d-4375-9beb-7d31d66afbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0884]], device='cuda:0', grad_fn=<MulBackward0>) tensor([[1.1221]], device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(pred_freq, pred_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b87f3de-b7e2-4a01-87a8-657cb73b7c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
