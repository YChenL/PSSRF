{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8b91fca-56f5-4299-9f41-95425732a49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:39: FutureWarning: Pass library_name=False as keyword args. From version 0.7 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import torchaudio\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", run_opts={\"device\":\"cuda\"})\n",
    "\n",
    "from speechbrain.pretrained import SpeakerRecognition\n",
    "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", run_opts={\"device\":\"cuda\"}, \n",
    "                                               savedir=\"pretrained_models/spkrec-ecapa-voxceleb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a7d386-1bb7-4d41-aa7e-488f055e2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import random\n",
    "\n",
    "from numpy.fft import fft, ifft\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058184e3-d430-4af7-adc3-8b7a673035b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimilarity(nn.Module):\n",
    "    def forward(self, tensor_1, tensor_2):\n",
    "        normalized_tensor_1 = tensor_1 / tensor_1.norm(dim=-1, keepdim=True)\n",
    "        normalized_tensor_2 = tensor_2 / tensor_2.norm(dim=-1, keepdim=True)\n",
    "        return (normalized_tensor_1 * normalized_tensor_2).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d738302c-7d5b-4ee9-9037-4ac78302ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_pitch(signal, fs, f_ratio):\n",
    "    \"\"\"\n",
    "    Calls psola pitch shifting algorithm\n",
    "    :param signal: original signal in the time-domain\n",
    "    :param fs: sample rate\n",
    "    :param f_ratio: ratio by which the frequency will be shifted\n",
    "    :return: pitch-shifted signal\n",
    "    \"\"\"\n",
    "    peaks = find_peaks(signal, fs)\n",
    "    new_signal = psola(signal, peaks, f_ratio)\n",
    "    return new_signal\n",
    "\n",
    "\n",
    "def find_peaks(signal, fs, max_hz=950, min_hz=75, analysis_win_ms=40, max_change=1.005, min_change=0.995):\n",
    "    \"\"\"\n",
    "    Find sample indices of peaks in time-domain signal\n",
    "    :param max_hz: maximum measured fundamental frequency\n",
    "    :param min_hz: minimum measured fundamental frequency\n",
    "    :param analysis_win_ms: window size used for autocorrelation analysis\n",
    "    :param max_change: restrict periodicity to not increase by more than this ratio from the mean\n",
    "    :param min_change: restrict periodicity to not decrease by more than this ratio from the mean\n",
    "    :return: peak indices\n",
    "    \"\"\"\n",
    "    N = len(signal)\n",
    "    min_period = fs // max_hz\n",
    "    max_period = fs // min_hz\n",
    "\n",
    "    # compute pitch periodicity\n",
    "    sequence = int(analysis_win_ms / 1000 * fs)  # analysis sequence length in samples\n",
    "    periods = compute_periods_per_sequence(signal, sequence, min_period, max_period, N)\n",
    "\n",
    "    # simple hack to avoid octave error: assume that the pitch should not vary much, restrict range\n",
    "    mean_period = np.mean(periods)\n",
    "    max_period = int(mean_period * 1.1)\n",
    "    min_period = int(mean_period * 0.9)\n",
    "    periods = compute_periods_per_sequence(signal, sequence, min_period, max_period, N)\n",
    "\n",
    "    # find the peaks\n",
    "    peaks = [np.argmax(signal[:int(periods[0]*1.1)])]\n",
    "    while True:\n",
    "        prev = peaks[-1]\n",
    "        idx = prev // sequence  # current autocorrelation analysis window\n",
    "        if prev + int(periods[idx] * max_change) >= N:\n",
    "            break\n",
    "        # find maximum near expected location\n",
    "        peaks.append(prev + int(periods[idx] * min_change) +\n",
    "                np.argmax(signal[prev + int(periods[idx] * min_change): prev + int(periods[idx] * max_change)]))\n",
    "    return np.array(peaks)\n",
    "\n",
    "\n",
    "def compute_periods_per_sequence(signal, sequence, min_period, max_period, N):\n",
    "    \"\"\"\n",
    "    Computes periodicity of a time-domain signal using autocorrelation\n",
    "    :param sequence: analysis window length in samples. Computes one periodicity value per window\n",
    "    :param min_period: smallest allowed periodicity\n",
    "    :param max_period: largest allowed periodicity\n",
    "    :return: list of measured periods in windows across the signal\n",
    "    \"\"\"\n",
    "    \n",
    "    offset = 0  # current sample offset\n",
    "    periods = []  # period length of each analysis sequence\n",
    "\n",
    "    while offset < N:\n",
    "        fourier = fft(signal[offset: offset + sequence])\n",
    "        fourier[0] = 0  # remove DC component\n",
    "        autoc = ifft(fourier * np.conj(fourier)).real\n",
    "        autoc_peak = min_period + np.argmax(autoc[min_period: max_period])\n",
    "        periods.append(autoc_peak)\n",
    "        offset += sequence\n",
    "    return periods\n",
    "\n",
    "\n",
    "def psola(signal, peaks, f_ratio):\n",
    "    \"\"\"\n",
    "    Time-Domain Pitch Synchronous Overlap and Add\n",
    "    :param signal: original time-domain signal\n",
    "    :param peaks: time-domain signal peak indices\n",
    "    :param f_ratio: pitch shift ratio\n",
    "    :return: pitch-shifted signal\n",
    "    \"\"\"\n",
    "    N = len(signal)\n",
    "    # Interpolate\n",
    "    new_signal = np.zeros(N)\n",
    "    new_peaks_ref = np.linspace(0, len(peaks) - 1, int(len(peaks) * f_ratio))\n",
    "    new_peaks = np.zeros(len(new_peaks_ref)).astype(int)\n",
    "\n",
    "    for i in range(len(new_peaks)):\n",
    "        weight = new_peaks_ref[i] % 1\n",
    "        left = np.floor(new_peaks_ref[i]).astype(int)\n",
    "        right = np.ceil(new_peaks_ref[i]).astype(int)\n",
    "        new_peaks[i] = int(peaks[left] * (1 - weight) + peaks[right] * weight)\n",
    "\n",
    "    # PSOLA\n",
    "    for j in range(len(new_peaks)):\n",
    "        # find the corresponding old peak index\n",
    "        i = np.argmin(np.abs(peaks - new_peaks[j]))\n",
    "        # get the distances to adjacent peaks\n",
    "        P1 = [new_peaks[j] if j == 0 else new_peaks[j] - new_peaks[j-1],\n",
    "              N - 1 - new_peaks[j] if j == len(new_peaks) - 1 else new_peaks[j+1] - new_peaks[j]]\n",
    "        # edge case truncation\n",
    "        if peaks[i] - P1[0] < 0:\n",
    "            P1[0] = peaks[i]\n",
    "        if peaks[i] + P1[1] > N - 1:\n",
    "            P1[1] = N - 1 - peaks[i]\n",
    "        # linear OLA window\n",
    "        window = list(np.linspace(0, 1, P1[0] + 1)[1:]) + list(np.linspace(1, 0, P1[1] + 1)[1:])\n",
    "        # center window from original signal at the new peak\n",
    "        new_signal[new_peaks[j] - P1[0]: new_peaks[j] + P1[1]] += window * signal[peaks[i] - P1[0]: peaks[i] + P1[1]]\n",
    "    return new_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9435f25-4064-42dc-b2dc-531b66bf4ca3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def revers_f(org_voice, dis_voice, sr, a):\n",
    "    '''\n",
    "    step 1: revers disguished voice\n",
    "    step 2: calculate similarity\n",
    "    '''\n",
    "    rev_vc = librosa.effects.pitch_shift(dis_voice, sr=sr, n_steps=-a, bins_per_octave=12)\n",
    "    org_voice = torch.from_numpy(org_voice).float()\n",
    "    rev_vc = torch.from_numpy(rev_vc).float()\n",
    "    org_emb = torch.tensor(classifier.encode_batch(org_voice))\n",
    "    rev_emb = torch.tensor(classifier.encode_batch(rev_vc))\n",
    "    sim = F.cosine_similarity(org_emb, rev_emb).mean()\n",
    "    return sim, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ca3bba3-6229-4148-9ce2-b2c34cf1c87f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TIFS(org_voice, dis_voice, sr):\n",
    "    org_sim = 0 \n",
    "    org_alpha = 0\n",
    "    for a in range(-8, 8, 1):\n",
    "        sim, alpha = revers_f(org_voice, dis_voice, sr, a)\n",
    "        if sim >= org_sim:\n",
    "            org_sim = sim\n",
    "            org_alpha = alpha\n",
    "            \n",
    "    return org_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "63c5ac44-8cf5-442d-8508-7a240fc1e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revers_f(org_voice, dis_voice, sr, a):\n",
    "    '''\n",
    "    step 1: revers disguished voice\n",
    "    step 2: calculate similarity\n",
    "    '''\n",
    "    rev_vc = librosa.effects.pitch_shift(dis_voice, sr=sr, n_steps=-a, bins_per_octave=12)\n",
    "    rev_vc = torch.from_numpy(rev_vc).float()\n",
    "    rev_emb = torch.tensor(classifier.encode_batch(rev_vc))\n",
    "    return rev_emb, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9fe121b-9f7d-43f7-9a29-7b36021fdd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revers_f_psola(org_voice, dis_voice, sr, a):\n",
    "    '''\n",
    "    step 1: revers disguished voice\n",
    "    step 2: calculate similarity\n",
    "    '''\n",
    "    # N = len(dis_voice)\n",
    "    f_ratio = 2 ** (-a / 12)\n",
    "    rev_vc = shift_pitch(dis_voice, sr, f_ratio)\n",
    "    org_voice = torch.from_numpy(org_voice).float()\n",
    "    rev_vc = torch.from_numpy(rev_vc).float()\n",
    "    org_emb = torch.tensor(classifier.encode_batch(org_voice))\n",
    "    rev_emb = torch.tensor(classifier.encode_batch(rev_vc))\n",
    "    sim = F.cosine_similarity(org_emb, rev_emb).mean()\n",
    "    return sim, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8e80295a-56bd-4099-b57d-b0f49ade2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TIFS(org_voice, dis_voice, sr):\n",
    "    org_sim = 0 \n",
    "    org_alpha = 0\n",
    "    org_voice = torch.from_numpy(org_voice).float()\n",
    "    org_emb = torch.tensor(classifier.encode_batch(org_voice))\n",
    "    \n",
    "    for a in range(-8, 8, 1):\n",
    "        rev_emb, alpha = revers_f(org_voice, dis_voice, sr, a)\n",
    "        sim = F.cosine_similarity(org_emb, rev_emb).mean()\n",
    "        if sim >= org_sim:\n",
    "            org_sim = sim\n",
    "            org_alpha = alpha\n",
    "            \n",
    "    return org_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f2584e-8092-4122-861e-02c1621582a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TIFS_psola(org_voice, dis_voice, sr):\n",
    "    org_sim = 0 \n",
    "    org_alpha = 0\n",
    "    for a in range(-8, 8, 1):\n",
    "        sim, alpha = revers_f_psola(org_voice, dis_voice, sr, a)\n",
    "        if sim >= org_sim:\n",
    "            org_sim = sim\n",
    "            org_alpha = alpha\n",
    "            \n",
    "    return org_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ad1d08-4058-4973-9bcb-02b819ea72ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepar_joint_spk(data_file):\n",
    "    file_list, file_org_list,label_list = [], [], []\n",
    "    with open(data_file, 'r', encoding='utf-8') as infile:\n",
    "        # file_list, label_list = [], []\n",
    "        for line in infile:\n",
    "            data_line = line.strip(\"\\n\").split()  # 去除首尾换行符，并按空格划分    \n",
    "            file_list.append(data_line[0])\n",
    "            file_org_list.append(data_line[1])\n",
    "            label_list.append(float(data_line[2]))\n",
    "   \n",
    "    return file_list, file_org_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "42a2b8c1-3d93-41a8-9ddb-5dc6c3c98c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files, org_files, test_labels = data_prepar_joint_spk('pitch_scaling_validation_seen_matlab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c5edd74e-522f-452c-a5e3-b5c57a76a2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10720"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "172ad599-d1a1-42d9-b716-39881d54156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "random.shuffle(test_files)\n",
    "\n",
    "random.seed(1234)\n",
    "random.shuffle(org_files)\n",
    "\n",
    "random.seed(1234)\n",
    "random.shuffle(test_labels)\n",
    "\n",
    "test_files = test_files[0:2000]\n",
    "org_files = org_files[0:2000]\n",
    "test_labels = test_labels[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "daf67d99-f663-4942-ae0e-b322aac89ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def est(test_files, org_files, test_labels):   \n",
    "    estimate_alpha, GT = [], []\n",
    "    i = 0\n",
    "    since = time.time()\n",
    "    for dis_v, org_v, label in zip(test_files, org_files, test_labels):          \n",
    "        dis_voice, dis_sr = librosa.load(dis_v) # , sr=22050\n",
    "        org_voice, _ = librosa.load(org_v) # , sr=22050\n",
    "        try:\n",
    "            predict_a = TIFS(org_voice, dis_voice, dis_sr)\n",
    "            # predict_a = TIFS_psola(org_voice, dis_voice, dis_sr)\n",
    "            estimate_alpha.append(predict_a) \n",
    "            GT.append(label) \n",
    "        except:\n",
    "            print(dis_v)\n",
    "        if i % 128 == 0:\n",
    "            time_elapsed = time.time() - since \n",
    "            print (int(i/128),'/',int(len(test_files)/128)) \n",
    "            print('Testing complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        i += 1\n",
    "     \n",
    "    label = torch.tensor(GT)\n",
    "    alpha = torch.tensor(estimate_alpha)\n",
    "    err = (alpha - label).abs().mean()\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bf717554-9035-4f4d-8046-ecd75c407e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYC\\AppData\\Local\\Temp/ipykernel_24268/3384545318.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  org_emb = torch.tensor(classifier.encode_batch(org_voice))\n",
      "C:\\Users\\LYC\\AppData\\Local\\Temp/ipykernel_24268/2554877969.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rev_emb = torch.tensor(classifier.encode_batch(rev_vc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 15\n",
      "Testing complete in 0m 1s\n",
      "1 / 15\n",
      "Testing complete in 3m 1s\n",
      "2 / 15\n",
      "Testing complete in 5m 57s\n",
      "3 / 15\n",
      "Testing complete in 9m 5s\n",
      "4 / 15\n",
      "Testing complete in 12m 1s\n",
      "5 / 15\n",
      "Testing complete in 15m 4s\n",
      "6 / 15\n",
      "Testing complete in 18m 9s\n",
      "7 / 15\n",
      "Testing complete in 21m 1s\n",
      "8 / 15\n",
      "Testing complete in 23m 53s\n",
      "9 / 15\n",
      "Testing complete in 26m 49s\n",
      "10 / 15\n",
      "Testing complete in 29m 40s\n",
      "11 / 15\n",
      "Testing complete in 32m 32s\n",
      "12 / 15\n",
      "Testing complete in 35m 20s\n",
      "13 / 15\n",
      "Testing complete in 38m 23s\n",
      "14 / 15\n",
      "Testing complete in 41m 18s\n",
      "15 / 15\n",
      "Testing complete in 44m 14s\n"
     ]
    }
   ],
   "source": [
    "err = est(test_files, org_files, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "21bf97d5-cbcf-4c08-9851-64eb8101a518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9793)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9794903-2a2d-4aa1-aabb-c607b88bd1e2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYC\\AppData\\Local\\Temp/ipykernel_19620/3443985595.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  org_emb = torch.tensor(classifier.encode_batch(org_voice))\n",
      "C:\\Users\\LYC\\AppData\\Local\\Temp/ipykernel_19620/3443985595.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rev_emb = torch.tensor(classifier.encode_batch(rev_vc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19620/3229240664.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdis_voice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdis_sr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdis_v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0morg_voice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morg_v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpredict_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTIFS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morg_voice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdis_voice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdis_sr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mestimate_alpha\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m128\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19620/3668498287.py\u001b[0m in \u001b[0;36mTIFS\u001b[1;34m(org_voice, dis_voice, sr)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0morg_alpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0msim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrevers_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morg_voice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdis_voice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0morg_sim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0morg_sim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19620/3443985595.py\u001b[0m in \u001b[0;36mrevers_f\u001b[1;34m(org_voice, dis_voice, sr, a)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstep\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcalculate\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     '''\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mrev_vc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpitch_shift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdis_voice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins_per_octave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0morg_voice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morg_voice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mrev_vc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrev_vc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\librosa\\util\\decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\librosa\\effects.py\u001b[0m in \u001b[0;36mpitch_shift\u001b[1;34m(y, sr, n_steps, bins_per_octave, res_type, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;31m# Stretch in time, then resample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     y_shift = core.resample(\n\u001b[1;32m--> 328\u001b[1;33m         \u001b[0mtime_stretch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m         \u001b[0morig_sr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[0mtarget_sr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\librosa\\util\\decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\librosa\\effects.py\u001b[0m in \u001b[0;36mtime_stretch\u001b[1;34m(y, rate, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;31m# Stretch by phase vocoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     stft_stretch = core.phase_vocoder(\n\u001b[0m\u001b[0;32m    245\u001b[0m         \u001b[0mstft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\librosa\\util\\decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\librosa\\core\\spectrum.py\u001b[0m in \u001b[0;36mphase_vocoder\u001b[1;34m(D, rate, hop_length, n_fft)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m         \u001b[1;31m# Wrap to -pi:pi range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1277\u001b[1;33m         \u001b[0mdphase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdphase\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdphase\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m         \u001b[1;31m# Accumulate phase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mround_\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mround_\u001b[1;34m(a, decimals, out)\u001b[0m\n\u001b[0;32m   3737\u001b[0m     \u001b[0maround\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mequivalent\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0msee\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3738\u001b[0m     \"\"\"\n\u001b[1;32m-> 3739\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0maround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maround\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36maround\u001b[1;34m(a, decimals, out)\u001b[0m\n\u001b[0;32m   3312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3313\u001b[0m     \"\"\"\n\u001b[1;32m-> 3314\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'round'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\pytorch19\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimate_alpha = []\n",
    "i= 0\n",
    "for dis_v, org_v in zip(test_files, org_files):       \n",
    "    dis_voice, dis_sr = librosa.load(dis_v)\n",
    "    org_voice, _ = librosa.load(org_v)\n",
    "    predict_a = TIFS(org_voice, dis_voice, dis_sr)\n",
    "    estimate_alpha.append(predict_a)     \n",
    "    if i % 128 == 0:\n",
    "        print (int(i/128),'/',int(len(test_files)/128)) \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d86ee1d-1ff8-4a31-a328-9fdb1d1ee31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3167c8fd-c793-4e6e-b77a-eb93a1a9d8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0988b-b52b-4e0c-819f-762331091ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "E:/datasets/project3/AISHELL-3/unseen_Audacity/-0.5\\SSB06930015.wav E:/datasets/project3/AISHELL-3/unseen/SSB0693\\SSB06930229.wav -0.5\n",
    "E:/datasets/project3/AISHELL-3/unseen_Audacity/4.5\\SSB10020405.wav E:/datasets/project3/AISHELL-3/unseen/SSB1002\\SSB10020246.wav 4.5\n",
    "E:/datasets/project3/AISHELL-3/unseen_Audacity/6.0\\SSB07170241.wav E:/datasets/project3/AISHELL-3/unseen/SSB0717\\SSB07170008.wav 6.0\n",
    "E:/datasets/project3/AISHELL-3/unseen_Audacity/6.0\\SSB07170246.wav E:/datasets/project3/AISHELL-3/unseen/SSB0717\\SSB07170471.wav 6.0\n",
    "E:/datasets/project3/AISHELL-3/unseen_Audacity/-6.5\\SSB09970303.wav E:/datasets/project3/AISHELL-3/unseen/SSB0997\\SSB09970006.wav -6.5\n",
    "E:/datasets/project3/AISHELL-3/unseen_Audacity/-6.5\\SSB09970370.wav E:/datasets/project3/AISHELL-3/unseen/SSB0997\\SSB09970291.wav -6.5\n",
    "E:/datasets/project3/AISHELL-3/unseen_Audacity/-6.5\\SSB09970450.wav E:/datasets/project3/AISHELL-3/unseen/SSB0997\\SSB09970124.wav -6.5\n",
    "E:/datasets/project3/AISHELL-3/unseen_Audacity/-6.5\\SSB10000040.wav E:/datasets/project3/AISHELL-3/unseen/SSB1000\\SSB10000320.wav -6.5\n",
    "E:/datasets/project3/AISHELL-3/unseen_Audacity/-3.0\\SSB10020039.wav E:/datasets/project3/AISHELL-3/unseen/SSB1002\\SSB10020011.wav -3.0\n",
    "E:/datasets/project3/AISHELL-3/unseen_Audacity/-3.0\\SSB10020045.wav E:/datasets/project3/AISHELL-3/unseen/SSB1002\\SSB10020425.wav -3.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
